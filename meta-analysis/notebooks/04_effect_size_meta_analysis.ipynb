{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Effect Size Meta-Analysis\n",
    "\n",
    "This notebook guides you through:\n",
    "1. Loading studies with effect sizes\n",
    "2. Running random-effects meta-analysis\n",
    "3. Assessing heterogeneity\n",
    "4. Creating forest and funnel plots\n",
    "5. Publication bias assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core import Study, EffectSize, MetaAnalysisDataset\n",
    "from analysis.effect_size import EffectSizeMetaAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Dataset with Effect Sizes\n",
    "\n",
    "Effect sizes can be extracted from papers or computed from summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with example studies\n",
    "dataset = MetaAnalysisDataset(\n",
    "    name=\"T-Maze Performance Effects\",\n",
    "    description=\"Meta-analysis of intervention effects on T-maze performance\"\n",
    ")\n",
    "\n",
    "# Example studies with effect sizes (Cohen's d)\n",
    "studies_data = [\n",
    "    {\n",
    "        \"study_id\": \"smith2020\",\n",
    "        \"title\": \"Cognitive training improves spatial navigation\",\n",
    "        \"authors\": [\"Smith, J.\", \"Jones, M.\"],\n",
    "        \"year\": 2020,\n",
    "        \"n_treatment\": 25,\n",
    "        \"n_control\": 25,\n",
    "        \"effect_size\": 0.65,\n",
    "        \"se\": 0.29\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"johnson2019\",\n",
    "        \"title\": \"Exercise and spatial memory\",\n",
    "        \"authors\": [\"Johnson, A.\"],\n",
    "        \"year\": 2019,\n",
    "        \"n_treatment\": 30,\n",
    "        \"n_control\": 32,\n",
    "        \"effect_size\": 0.42,\n",
    "        \"se\": 0.26\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"chen2021\",\n",
    "        \"title\": \"Virtual reality training for navigation\",\n",
    "        \"authors\": [\"Chen, L.\", \"Wang, X.\"],\n",
    "        \"year\": 2021,\n",
    "        \"n_treatment\": 40,\n",
    "        \"n_control\": 38,\n",
    "        \"effect_size\": 0.78,\n",
    "        \"se\": 0.23\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"garcia2022\",\n",
    "        \"title\": \"Mindfulness and spatial cognition\",\n",
    "        \"authors\": [\"Garcia, R.\"],\n",
    "        \"year\": 2022,\n",
    "        \"n_treatment\": 22,\n",
    "        \"n_control\": 20,\n",
    "        \"effect_size\": 0.31,\n",
    "        \"se\": 0.31\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"kim2023\",\n",
    "        \"title\": \"Sleep and navigation performance\",\n",
    "        \"authors\": [\"Kim, S.\", \"Lee, H.\"],\n",
    "        \"year\": 2023,\n",
    "        \"n_treatment\": 35,\n",
    "        \"n_control\": 35,\n",
    "        \"effect_size\": 0.55,\n",
    "        \"se\": 0.24\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"wilson2021\",\n",
    "        \"title\": \"Neurofeedback and spatial skills\",\n",
    "        \"authors\": [\"Wilson, P.\"],\n",
    "        \"year\": 2021,\n",
    "        \"n_treatment\": 28,\n",
    "        \"n_control\": 30,\n",
    "        \"effect_size\": 0.48,\n",
    "        \"se\": 0.27\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"taylor2020\",\n",
    "        \"title\": \"Working memory training transfer\",\n",
    "        \"authors\": [\"Taylor, M.\", \"Brown, K.\"],\n",
    "        \"year\": 2020,\n",
    "        \"n_treatment\": 45,\n",
    "        \"n_control\": 42,\n",
    "        \"effect_size\": 0.38,\n",
    "        \"se\": 0.22\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"martinez2022\",\n",
    "        \"title\": \"Aerobic exercise and hippocampal function\",\n",
    "        \"authors\": [\"Martinez, C.\"],\n",
    "        \"year\": 2022,\n",
    "        \"n_treatment\": 50,\n",
    "        \"n_control\": 50,\n",
    "        \"effect_size\": 0.62,\n",
    "        \"se\": 0.20\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create studies with effect sizes\n",
    "for data in studies_data:\n",
    "    # Calculate variance from SE\n",
    "    variance = data[\"se\"] ** 2\n",
    "    \n",
    "    study = Study(\n",
    "        study_id=data[\"study_id\"],\n",
    "        title=data[\"title\"],\n",
    "        authors=data[\"authors\"],\n",
    "        year=data[\"year\"],\n",
    "        n_total=data[\"n_treatment\"] + data[\"n_control\"],\n",
    "        n_treatment=data[\"n_treatment\"],\n",
    "        n_control=data[\"n_control\"],\n",
    "        effect_sizes=[\n",
    "            EffectSize(\n",
    "                effect_size=data[\"effect_size\"],\n",
    "                variance=variance,\n",
    "                effect_type=\"d\",\n",
    "                outcome_name=\"T-maze accuracy\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    dataset.add_study(study)\n",
    "\n",
    "print(f\"Created dataset with {dataset.n_studies} studies\")\n",
    "print(dataset.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View effect sizes\n",
    "es_df = dataset.to_effect_sizes_df()\n",
    "es_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Computing Effect Sizes from Raw Data\n",
    "\n",
    "If papers report means and SDs instead of effect sizes, you can compute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Computing Cohen's d from means and SDs\n",
    "from core import EffectSize\n",
    "\n",
    "# Raw data from a hypothetical paper\n",
    "mean_treatment = 85.2\n",
    "sd_treatment = 12.4\n",
    "n_treatment = 30\n",
    "\n",
    "mean_control = 78.5\n",
    "sd_control = 11.8\n",
    "n_control = 28\n",
    "\n",
    "# Use the from_means_sds class method\n",
    "computed_es = EffectSize.from_means_sds(\n",
    "    mean_exp=mean_treatment,\n",
    "    sd_exp=sd_treatment,\n",
    "    n_exp=n_treatment,\n",
    "    mean_ctrl=mean_control,\n",
    "    sd_ctrl=sd_control,\n",
    "    n_ctrl=n_control,\n",
    "    outcome_name=\"Computed example\"\n",
    ")\n",
    "\n",
    "print(f\"Computed effect size (Cohen's d): {computed_es.effect_size:.3f}\")\n",
    "print(f\"Standard error: {np.sqrt(computed_es.variance):.3f}\")\n",
    "print(f\"95% CI: [{computed_es.effect_size - 1.96*np.sqrt(computed_es.variance):.3f}, \"\n",
    "      f\"{computed_es.effect_size + 1.96*np.sqrt(computed_es.variance):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Computing from t-statistic\n",
    "t_value = 2.85\n",
    "n1 = 25\n",
    "n2 = 25\n",
    "\n",
    "es_from_t = EffectSize.from_t_statistic(\n",
    "    t=t_value,\n",
    "    n1=n1,\n",
    "    n2=n2,\n",
    "    outcome_name=\"From t-stat\"\n",
    ")\n",
    "\n",
    "print(f\"Effect size from t={t_value}: d = {es_from_t.effect_size:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Random-Effects Meta-Analysis\n",
    "\n",
    "We'll use the DerSimonian-Laird estimator for between-study variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize meta-analysis\n",
    "try:\n",
    "    ma = EffectSizeMetaAnalysis(dataset)\n",
    "    print(\"Meta-analysis initialized successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nInstall PyMARE with: pip install pymare\")\n",
    "    ma = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis\n",
    "if ma is not None:\n",
    "    results = ma.run(\n",
    "        method=\"DL\",      # DerSimonian-Laird (most common)\n",
    "        ci_level=0.95     # 95% confidence interval\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"META-ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nCombined Effect Size (d): {results['combined_effect']:.3f}\")\n",
    "    print(f\"95% CI: [{results['combined_ci'][0]:.3f}, {results['combined_ci'][1]:.3f}]\")\n",
    "    print(f\"Z = {results['combined_z']:.2f}, p = {results['combined_pvalue']:.4f}\")\n",
    "    print(f\"\\nHeterogeneity:\")\n",
    "    print(f\"  Q = {results['q_statistic']:.2f} (p = {results['q_pvalue']:.4f})\")\n",
    "    print(f\"  I\u00b2 = {results['i_squared']:.1f}%\")\n",
    "    print(f\"  \u03c4\u00b2 = {results['tau_squared']:.4f}\")\n",
    "    print(f\"  \u03c4  = {results['tau']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret I-squared\n",
    "if ma is not None:\n",
    "    i2 = results['i_squared']\n",
    "    \n",
    "    print(\"\\nHeterogeneity Interpretation:\")\n",
    "    if i2 < 25:\n",
    "        print(f\"  I\u00b2 = {i2:.1f}% indicates LOW heterogeneity\")\n",
    "        print(\"  Studies are relatively consistent\")\n",
    "    elif i2 < 50:\n",
    "        print(f\"  I\u00b2 = {i2:.1f}% indicates MODERATE heterogeneity\")\n",
    "        print(\"  Some variation between studies\")\n",
    "    elif i2 < 75:\n",
    "        print(f\"  I\u00b2 = {i2:.1f}% indicates SUBSTANTIAL heterogeneity\")\n",
    "        print(\"  Consider exploring moderators\")\n",
    "    else:\n",
    "        print(f\"  I\u00b2 = {i2:.1f}% indicates CONSIDERABLE heterogeneity\")\n",
    "        print(\"  Strong variation - subgroup analysis recommended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Forest Plot\n",
    "\n",
    "Visualize individual study effects and the combined estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forest plot\n",
    "if ma is not None:\n",
    "    fig = ma.forest_plot(\n",
    "        title=\"Forest Plot: Intervention Effects on T-Maze Performance\",\n",
    "        effect_label=\"Cohen's d\",\n",
    "        show_weights=True\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom forest plot with more control\n",
    "if ma is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    es_df = dataset.to_effect_sizes_df()\n",
    "    n_studies = len(es_df)\n",
    "    \n",
    "    # Sort by effect size\n",
    "    es_df = es_df.sort_values('effect_size', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    for i, row in es_df.iterrows():\n",
    "        es = row['effect_size']\n",
    "        se = np.sqrt(row['variance'])\n",
    "        ci_low = es - 1.96 * se\n",
    "        ci_high = es + 1.96 * se\n",
    "        \n",
    "        # CI line\n",
    "        ax.hlines(i, ci_low, ci_high, colors='steelblue', linewidth=2)\n",
    "        # Point\n",
    "        ax.scatter(es, i, s=100, color='steelblue', zorder=3)\n",
    "        # Label\n",
    "        ax.text(-0.1, i, row['study_id'], ha='right', va='center', fontsize=10)\n",
    "    \n",
    "    # Combined effect\n",
    "    combined = results['combined_effect']\n",
    "    ci = results['combined_ci']\n",
    "    ax.axvline(x=combined, color='red', linestyle='-', linewidth=2, alpha=0.7, label='Combined')\n",
    "    ax.axvspan(ci[0], ci[1], alpha=0.2, color='red')\n",
    "    \n",
    "    # Null line\n",
    "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "    \n",
    "    ax.set_yticks(range(n_studies))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xlabel(\"Cohen's d\", fontsize=12)\n",
    "    ax.set_title(\"Forest Plot (sorted by effect size)\", fontsize=14)\n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Funnel Plot & Publication Bias\n",
    "\n",
    "Check for asymmetry that might indicate publication bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create funnel plot\n",
    "if ma is not None:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    es_df = dataset.to_effect_sizes_df()\n",
    "    \n",
    "    effects = es_df['effect_size'].values\n",
    "    se = np.sqrt(es_df['variance'].values)\n",
    "    \n",
    "    # Plot studies\n",
    "    ax.scatter(effects, se, s=80, alpha=0.7, edgecolors='black')\n",
    "    \n",
    "    # Combined effect line\n",
    "    combined = results['combined_effect']\n",
    "    ax.axvline(x=combined, color='red', linestyle='-', linewidth=2, label='Combined effect')\n",
    "    \n",
    "    # Pseudo-confidence limits\n",
    "    se_range = np.linspace(0.01, max(se) * 1.1, 100)\n",
    "    ax.plot(combined - 1.96 * se_range, se_range, 'k--', alpha=0.5)\n",
    "    ax.plot(combined + 1.96 * se_range, se_range, 'k--', alpha=0.5)\n",
    "    \n",
    "    # Fill the funnel\n",
    "    ax.fill_betweenx(se_range, \n",
    "                     combined - 1.96 * se_range, \n",
    "                     combined + 1.96 * se_range,\n",
    "                     alpha=0.1, color='gray')\n",
    "    \n",
    "    ax.set_xlabel(\"Effect Size (d)\", fontsize=12)\n",
    "    ax.set_ylabel(\"Standard Error\", fontsize=12)\n",
    "    ax.set_title(\"Funnel Plot\", fontsize=14)\n",
    "    ax.invert_yaxis()  # Larger studies at top\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"- A symmetric funnel suggests no publication bias\")\n",
    "    print(\"- Asymmetry (e.g., missing studies in bottom-left) may indicate bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egger's test for funnel plot asymmetry\n",
    "from scipy import stats\n",
    "\n",
    "if ma is not None:\n",
    "    es_df = dataset.to_effect_sizes_df()\n",
    "    \n",
    "    effects = es_df['effect_size'].values\n",
    "    se = np.sqrt(es_df['variance'].values)\n",
    "    precision = 1 / se\n",
    "    \n",
    "    # Egger's regression: regress standardized effect on precision\n",
    "    standardized = effects / se\n",
    "    slope, intercept, r, p, stderr = stats.linregress(precision, standardized)\n",
    "    \n",
    "    print(\"Egger's Test for Publication Bias\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Intercept: {intercept:.3f}\")\n",
    "    print(f\"SE: {stderr:.3f}\")\n",
    "    print(f\"t = {intercept/stderr:.2f}\")\n",
    "    print(f\"p = {p:.4f}\")\n",
    "    print()\n",
    "    if p < 0.05:\n",
    "        print(\"Result: Significant asymmetry detected (p < 0.05)\")\n",
    "        print(\"Interpretation: Possible publication bias\")\n",
    "    else:\n",
    "        print(\"Result: No significant asymmetry (p >= 0.05)\")\n",
    "        print(\"Interpretation: No strong evidence of publication bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-one-out analysis\n",
    "if ma is not None:\n",
    "    print(\"Leave-One-Out Sensitivity Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    es_df = dataset.to_effect_sizes_df()\n",
    "    original_combined = results['combined_effect']\n",
    "    \n",
    "    loo_results = []\n",
    "    \n",
    "    for i in range(len(es_df)):\n",
    "        # Create dataset without study i\n",
    "        subset_effects = np.delete(es_df['effect_size'].values, i)\n",
    "        subset_variance = np.delete(es_df['variance'].values, i)\n",
    "        \n",
    "        # Simple DL calculation\n",
    "        w = 1 / subset_variance\n",
    "        combined = np.sum(w * subset_effects) / np.sum(w)\n",
    "        \n",
    "        study_id = es_df.iloc[i]['study_id']\n",
    "        change = combined - original_combined\n",
    "        \n",
    "        loo_results.append({\n",
    "            'Excluded': study_id,\n",
    "            'Combined_d': combined,\n",
    "            'Change': change\n",
    "        })\n",
    "    \n",
    "    loo_df = pd.DataFrame(loo_results)\n",
    "    loo_df = loo_df.sort_values('Change', key=abs, ascending=False)\n",
    "    \n",
    "    print(f\"\\nOriginal combined effect: {original_combined:.3f}\")\n",
    "    print(f\"\\nWhen excluding each study:\")\n",
    "    print(loo_df.to_string(index=False))\n",
    "    \n",
    "    # Check if any exclusion changes conclusion\n",
    "    max_change = loo_df['Change'].abs().max()\n",
    "    print(f\"\\nMaximum change: {max_change:.3f}\")\n",
    "    print(\"Most influential study:\", loo_df.iloc[0]['Excluded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different estimation methods\n",
    "if ma is not None:\n",
    "    methods = [\"DL\", \"HE\", \"FE\"]\n",
    "    method_names = {\n",
    "        \"DL\": \"DerSimonian-Laird\",\n",
    "        \"HE\": \"Hedges\",\n",
    "        \"FE\": \"Fixed Effects\"\n",
    "    }\n",
    "    \n",
    "    print(\"Comparison of Estimation Methods\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    comparison = []\n",
    "    for method in methods:\n",
    "        try:\n",
    "            r = ma.run(method=method)\n",
    "            comparison.append({\n",
    "                'Method': method_names[method],\n",
    "                'Effect': r['combined_effect'],\n",
    "                'CI_lower': r['combined_ci'][0],\n",
    "                'CI_upper': r['combined_ci'][1],\n",
    "                'tau2': r['tau_squared']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"  {method}: Error - {e}\")\n",
    "    \n",
    "    comp_df = pd.DataFrame(comparison)\n",
    "    print(comp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../results/effect_size\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if ma is not None:\n",
    "    # Save forest plot\n",
    "    fig = ma.forest_plot(title=\"Forest Plot\")\n",
    "    fig.savefig(output_dir / \"forest_plot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved forest plot to {output_dir / 'forest_plot.png'}\")\n",
    "    \n",
    "    # Save effect sizes table\n",
    "    es_df = dataset.to_effect_sizes_df()\n",
    "    es_df.to_csv(output_dir / \"effect_sizes.csv\", index=False)\n",
    "    print(f\"Saved effect sizes to {output_dir / 'effect_sizes.csv'}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = ma.summary()\n",
    "    with open(output_dir / \"summary.txt\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    print(f\"Saved summary to {output_dir / 'summary.txt'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "if ma is not None:\n",
    "    print(ma.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Creating a dataset with effect sizes\n",
    "2. Computing effect sizes from summary statistics\n",
    "3. Running random-effects meta-analysis\n",
    "4. Interpreting heterogeneity (I\u00b2, Q, \u03c4\u00b2)\n",
    "5. Creating forest and funnel plots\n",
    "6. Assessing publication bias\n",
    "7. Sensitivity analysis\n",
    "\n",
    "### Next Steps\n",
    "- Add moderator analysis (meta-regression)\n",
    "- Explore subgroup differences\n",
    "- Combine with coordinate analysis from notebook 03"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
