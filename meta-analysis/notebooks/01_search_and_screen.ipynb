{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Search and Screen Papers\n",
    "\n",
    "This notebook guides you through:\n",
    "1. Defining your research question and inclusion criteria\n",
    "2. Searching PubMed for relevant papers\n",
    "3. AI-assisted abstract screening\n",
    "4. Tracking decisions for PRISMA reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - add parent directory to path\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Your Research Question\n",
    "\n",
    "Use the PICO framework:\n",
    "- **P**opulation: Who are you studying?\n",
    "- **I**ntervention: What exposure/treatment?\n",
    "- **C**omparison: What is the control condition?\n",
    "- **O**utcome: What are you measuring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your research question\n",
    "RESEARCH_QUESTION = \"What brain regions are activated during spatial decision-making in T-maze tasks?\"\n",
    "\n",
    "PICO = {\n",
    "    \"Population\": \"Healthy adult humans\",\n",
    "    \"Intervention\": \"T-maze or spatial decision-making task\",\n",
    "    \"Comparison\": \"Control condition or baseline\",\n",
    "    \"Outcome\": \"Brain activation (fMRI coordinates)\"\n",
    "}\n",
    "\n",
    "print(\"Research Question:\")\n",
    "print(f\"  {RESEARCH_QUESTION}\")\n",
    "print(\"\\nPICO:\")\n",
    "for key, value in PICO.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Inclusion/Exclusion Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUSION_CRITERIA = [\n",
    "    \"Reports original fMRI or PET neuroimaging data\",\n",
    "    \"Uses T-maze, spatial navigation, or decision-making task\",\n",
    "    \"Reports activation coordinates in MNI or Talairach space\",\n",
    "    \"Published in peer-reviewed journal\",\n",
    "    \"Human participants\",\n",
    "    \"Written in English\"\n",
    "]\n",
    "\n",
    "EXCLUSION_CRITERIA = [\n",
    "    \"Review articles or meta-analyses without original data\",\n",
    "    \"Case studies with n < 5\",\n",
    "    \"Only ROI analysis (no whole-brain coordinates)\",\n",
    "    \"Clinical populations only (unless healthy control group)\",\n",
    "    \"Animal studies\"\n",
    "]\n",
    "\n",
    "print(\"Inclusion Criteria:\")\n",
    "for i, c in enumerate(INCLUSION_CRITERIA, 1):\n",
    "    print(f\"  {i}. {c}\")\n",
    "\n",
    "print(\"\\nExclusion Criteria:\")\n",
    "for i, c in enumerate(EXCLUSION_CRITERIA, 1):\n",
    "    print(f\"  {i}. {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Search PubMed\n",
    "\n",
    "Build your search query and retrieve abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build PubMed search query\n",
    "SEARCH_TERMS = [\n",
    "    '(\"T-maze\" OR \"T maze\" OR \"spatial decision\" OR \"spatial navigation\")',\n",
    "    '(fMRI OR \"functional MRI\" OR \"functional magnetic resonance\")',\n",
    "    '(activation OR BOLD OR \"brain activity\")'\n",
    "]\n",
    "\n",
    "SEARCH_QUERY = \" AND \".join(SEARCH_TERMS)\n",
    "print(\"Search Query:\")\n",
    "print(SEARCH_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search PubMed using Biopython\n",
    "from Bio import Entrez\n",
    "\n",
    "# Set your email (required by NCBI)\n",
    "Entrez.email = \"your-email@example.com\"  # CHANGE THIS\n",
    "\n",
    "def search_pubmed(query, max_results=100):\n",
    "    \"\"\"Search PubMed and return paper metadata.\"\"\"\n",
    "    # Search\n",
    "    handle = Entrez.esearch(\n",
    "        db=\"pubmed\",\n",
    "        term=query,\n",
    "        retmax=max_results,\n",
    "        sort=\"relevance\"\n",
    "    )\n",
    "    results = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    \n",
    "    pmids = results[\"IdList\"]\n",
    "    print(f\"Found {len(pmids)} papers\")\n",
    "    \n",
    "    if not pmids:\n",
    "        return []\n",
    "    \n",
    "    # Fetch details\n",
    "    handle = Entrez.efetch(\n",
    "        db=\"pubmed\",\n",
    "        id=\",\".join(pmids),\n",
    "        rettype=\"xml\"\n",
    "    )\n",
    "    records = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    \n",
    "    papers = []\n",
    "    for article in records[\"PubmedArticle\"]:\n",
    "        try:\n",
    "            medline = article[\"MedlineCitation\"]\n",
    "            article_data = medline[\"Article\"]\n",
    "            \n",
    "            # Get authors\n",
    "            authors = []\n",
    "            if \"AuthorList\" in article_data:\n",
    "                for author in article_data[\"AuthorList\"]:\n",
    "                    if \"LastName\" in author:\n",
    "                        name = author[\"LastName\"]\n",
    "                        if \"Initials\" in author:\n",
    "                            name += \" \" + author[\"Initials\"]\n",
    "                        authors.append(name)\n",
    "            \n",
    "            # Get abstract\n",
    "            abstract = \"\"\n",
    "            if \"Abstract\" in article_data:\n",
    "                abstract_texts = article_data[\"Abstract\"][\"AbstractText\"]\n",
    "                if isinstance(abstract_texts, list):\n",
    "                    abstract = \" \".join(str(t) for t in abstract_texts)\n",
    "                else:\n",
    "                    abstract = str(abstract_texts)\n",
    "            \n",
    "            papers.append({\n",
    "                \"pmid\": str(medline[\"PMID\"]),\n",
    "                \"title\": str(article_data[\"ArticleTitle\"]),\n",
    "                \"authors\": \"; \".join(authors[:3]) + (\" et al.\" if len(authors) > 3 else \"\"),\n",
    "                \"year\": int(medline[\"DateCompleted\"][\"Year\"]) if \"DateCompleted\" in medline else None,\n",
    "                \"abstract\": abstract,\n",
    "                \"journal\": str(article_data[\"Journal\"][\"Title\"])\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return papers\n",
    "\n",
    "# Run search\n",
    "papers = search_pubmed(SEARCH_QUERY, max_results=50)\n",
    "print(f\"\\nRetrieved {len(papers)} papers with abstracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first few papers\n",
    "papers_df = pd.DataFrame(papers)\n",
    "papers_df[[\"pmid\", \"title\", \"year\", \"authors\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: AI-Assisted Screening\n",
    "\n",
    "Use Claude to screen abstracts against your criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from extraction.extractors.base_extractor import LLMProvider\n",
    "\n",
    "# Initialize LLM\n",
    "# Make sure ANTHROPIC_API_KEY is set in environment\n",
    "llm = LLMProvider(provider=\"anthropic\")\n",
    "\n",
    "SCREENING_PROMPT = \"\"\"You are screening abstracts for a meta-analysis.\n",
    "\n",
    "Research Question: {question}\n",
    "\n",
    "INCLUSION CRITERIA:\n",
    "{inclusion}\n",
    "\n",
    "EXCLUSION CRITERIA:\n",
    "{exclusion}\n",
    "\n",
    "Abstract to screen:\n",
    "Title: {title}\n",
    "Year: {year}\n",
    "Abstract: {abstract}\n",
    "\n",
    "Based on the abstract, determine:\n",
    "1. INCLUDE, EXCLUDE, or UNCERTAIN\n",
    "2. Which criteria are met/not met\n",
    "3. Brief reasoning\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "    \"decision\": \"INCLUDE\" | \"EXCLUDE\" | \"UNCERTAIN\",\n",
    "    \"confidence\": 0.0-1.0,\n",
    "    \"reasoning\": \"brief explanation\",\n",
    "    \"criteria_met\": [\"list of met inclusion criteria\"],\n",
    "    \"exclusion_reasons\": [\"list of exclusion reasons, if any\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def screen_abstract(paper):\n",
    "    \"\"\"Screen a single abstract.\"\"\"\n",
    "    prompt = SCREENING_PROMPT.format(\n",
    "        question=RESEARCH_QUESTION,\n",
    "        inclusion=\"\\n\".join(f\"- {c}\" for c in INCLUSION_CRITERIA),\n",
    "        exclusion=\"\\n\".join(f\"- {c}\" for c in EXCLUSION_CRITERIA),\n",
    "        title=paper[\"title\"],\n",
    "        year=paper[\"year\"],\n",
    "        abstract=paper[\"abstract\"]\n",
    "    )\n",
    "    \n",
    "    result = llm.extract(paper[\"abstract\"], prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen papers (this will make API calls - costs money!)\n",
    "# For demo, just screen first 5\n",
    "from tqdm import tqdm\n",
    "\n",
    "screening_results = []\n",
    "\n",
    "for paper in tqdm(papers[:5], desc=\"Screening\"):\n",
    "    try:\n",
    "        result = screen_abstract(paper)\n",
    "        result[\"pmid\"] = paper[\"pmid\"]\n",
    "        result[\"title\"] = paper[\"title\"]\n",
    "        screening_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error screening {paper['pmid']}: {e}\")\n",
    "\n",
    "screening_df = pd.DataFrame(screening_results)\n",
    "screening_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Review and Export\n",
    "\n",
    "Review screening decisions and export included papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of screening\n",
    "if len(screening_results) > 0:\n",
    "    print(\"Screening Summary:\")\n",
    "    print(screening_df[\"decision\"].value_counts())\n",
    "    \n",
    "    # Get included papers\n",
    "    included = screening_df[screening_df[\"decision\"] == \"INCLUDE\"]\n",
    "    print(f\"\\nIncluded: {len(included)} papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_dir = Path(\"../data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "papers_df.to_csv(output_dir / \"search_results.csv\", index=False)\n",
    "if len(screening_results) > 0:\n",
    "    screening_df.to_csv(output_dir / \"screening_results.csv\", index=False)\n",
    "    \n",
    "print(f\"Saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Review UNCERTAIN papers manually\n",
    "2. Get full-text PDFs for INCLUDED papers\n",
    "3. Proceed to notebook 02 for data extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
