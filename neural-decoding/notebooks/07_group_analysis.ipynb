{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Group Analysis\n",
    "\n",
    "Multi-subject decoding analysis and statistical inference.\n",
    "\n",
    "**Contents:**\n",
    "1. Within-subject decoding (each subject separately)\n",
    "2. Group-level statistics\n",
    "3. Leave-one-subject-out analysis\n",
    "4. Subject-specific vs. common patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from core.dataset import DecodingDataset\n",
    "from models.classifiers import SVMDecoder\n",
    "from validation.cross_validation import LeaveOneRunOut, LeaveOneSubjectOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multi-Subject Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multi-subject data\n",
    "n_subjects = 15\n",
    "n_runs_per_subject = 4\n",
    "n_trials_per_run = 30\n",
    "n_features = 500\n",
    "\n",
    "# Store subject datasets\n",
    "subject_datasets = []\n",
    "\n",
    "for subj in range(n_subjects):\n",
    "    # Subject-specific signal strength (variability)\n",
    "    signal_strength = 0.5 + np.random.rand() * 0.5\n",
    "    \n",
    "    X, y = make_classification(\n",
    "        n_samples=n_runs_per_subject * n_trials_per_run,\n",
    "        n_features=n_features,\n",
    "        n_informative=30,\n",
    "        n_classes=2,\n",
    "        class_sep=signal_strength,\n",
    "        random_state=subj * 42\n",
    "    )\n",
    "    \n",
    "    runs = np.repeat(np.arange(1, n_runs_per_subject + 1), n_trials_per_run)\n",
    "    \n",
    "    dataset = DecodingDataset(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        groups=runs,\n",
    "        class_names=[\"class_A\", \"class_B\"],\n",
    "        metadata={\"subject\": subj + 1},\n",
    "        modality=\"fmri\"\n",
    "    )\n",
    "    subject_datasets.append(dataset)\n",
    "\n",
    "print(f\"Created {n_subjects} subject datasets\")\n",
    "print(f\"Each: {subject_datasets[0].n_samples} samples, {subject_datasets[0].n_features} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Within-Subject Decoding\n",
    "\n",
    "Decode each subject separately, then aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode each subject\n",
    "decoder = SVMDecoder(kernel=\"linear\")\n",
    "loro_cv = LeaveOneRunOut()\n",
    "\n",
    "subject_accuracies = []\n",
    "subject_results = []\n",
    "\n",
    "for i, dataset in enumerate(subject_datasets):\n",
    "    results = decoder.cross_validate(dataset, cv=loro_cv)\n",
    "    subject_accuracies.append(results.accuracy)\n",
    "    subject_results.append(results)\n",
    "    print(f\"Subject {i+1}: {results.accuracy:.1%}\")\n",
    "\n",
    "subject_accuracies = np.array(subject_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group-level summary\n",
    "print(f\"\\nGroup Results:\")\n",
    "print(f\"  Mean: {np.mean(subject_accuracies):.1%}\")\n",
    "print(f\"  Std: {np.std(subject_accuracies):.1%}\")\n",
    "print(f\"  Min: {np.min(subject_accuracies):.1%}\")\n",
    "print(f\"  Max: {np.max(subject_accuracies):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Group-Level Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample t-test against chance (50%)\n",
    "chance = 0.5\n",
    "t_stat, p_value = stats.ttest_1samp(subject_accuracies, chance)\n",
    "\n",
    "print(f\"One-sample t-test vs chance ({chance:.0%}):\")\n",
    "print(f\"  t = {t_stat:.3f}\")\n",
    "print(f\"  p = {p_value:.4f}\")\n",
    "print(f\"  Significant (p<0.05): {p_value < 0.05}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-parametric: Wilcoxon signed-rank test\n",
    "w_stat, w_pvalue = stats.wilcoxon(subject_accuracies - chance)\n",
    "\n",
    "print(f\"\\nWilcoxon signed-rank test:\")\n",
    "print(f\"  W = {w_stat:.1f}\")\n",
    "print(f\"  p = {w_pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap confidence interval\n",
    "n_bootstrap = 1000\n",
    "boot_means = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    boot_sample = np.random.choice(subject_accuracies, size=n_subjects, replace=True)\n",
    "    boot_means.append(np.mean(boot_sample))\n",
    "\n",
    "ci_lower = np.percentile(boot_means, 2.5)\n",
    "ci_upper = np.percentile(boot_means, 97.5)\n",
    "\n",
    "print(f\"\\n95% Bootstrap CI: [{ci_lower:.1%}, {ci_upper:.1%}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot subject accuracies\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar plot\n",
    "ax = axes[0]\n",
    "subjects = np.arange(1, n_subjects + 1)\n",
    "ax.bar(subjects, subject_accuracies, color='steelblue', edgecolor='black')\n",
    "ax.axhline(y=chance, color='red', linestyle='--', label='Chance')\n",
    "ax.axhline(y=np.mean(subject_accuracies), color='green', linestyle='-', \n",
    "           label=f'Mean: {np.mean(subject_accuracies):.1%}')\n",
    "ax.set_xlabel('Subject')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Individual Subject Accuracies')\n",
    "ax.set_xticks(subjects)\n",
    "ax.legend()\n",
    "\n",
    "# Box plot\n",
    "ax = axes[1]\n",
    "ax.boxplot(subject_accuracies, vert=True)\n",
    "ax.axhline(y=chance, color='red', linestyle='--', label='Chance')\n",
    "ax.scatter([1] * n_subjects, subject_accuracies, alpha=0.5)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Group Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Leave-One-Subject-Out Analysis\n",
    "\n",
    "Train on N-1 subjects, test on held-out subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all subjects into one dataset\n",
    "X_all = np.vstack([d.X for d in subject_datasets])\n",
    "y_all = np.concatenate([d.y for d in subject_datasets])\n",
    "subjects_all = np.concatenate([\n",
    "    np.full(d.n_samples, d.metadata['subject']) \n",
    "    for d in subject_datasets\n",
    "])\n",
    "\n",
    "combined_dataset = DecodingDataset(\n",
    "    X=X_all,\n",
    "    y=y_all,\n",
    "    groups=subjects_all,\n",
    "    class_names=[\"class_A\", \"class_B\"],\n",
    "    modality=\"fmri\"\n",
    ")\n",
    "\n",
    "print(f\"Combined dataset: {combined_dataset.n_samples} samples\")\n",
    "print(f\"Subjects: {np.unique(subjects_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSO cross-validation\n",
    "loso_cv = LeaveOneSubjectOut()\n",
    "results_loso = decoder.cross_validate(combined_dataset, cv=loso_cv)\n",
    "\n",
    "print(f\"\\nLeave-One-Subject-Out Results:\")\n",
    "print(f\"  Mean accuracy: {results_loso.accuracy:.1%}\")\n",
    "print(f\"  Std: {results_loso.cv_std:.1%}\")\n",
    "print(f\"\\nPer-subject (held-out) accuracies:\")\n",
    "for i, acc in enumerate(results_loso.cv_scores):\n",
    "    print(f\"  Subject {i+1}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare within-subject vs. LOSO\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(n_subjects)\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, subject_accuracies, width, label='Within-Subject', color='steelblue')\n",
    "ax.bar(x + width/2, results_loso.cv_scores, width, label='LOSO', color='coral')\n",
    "\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', label='Chance')\n",
    "ax.set_xlabel('Subject')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Within-Subject vs. Leave-One-Subject-Out')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'S{i+1}' for i in range(n_subjects)])\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Subject-Specific vs. Common Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between within-subject and LOSO performance\n",
    "correlation = np.corrcoef(subject_accuracies, results_loso.cv_scores)[0, 1]\n",
    "\n",
    "print(f\"Correlation between within-subject and LOSO: r = {correlation:.3f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  High correlation: Similar patterns across subjects\")\n",
    "print(\"  Low correlation: Subject-specific patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "ax.scatter(subject_accuracies, results_loso.cv_scores, s=100, alpha=0.7)\n",
    "\n",
    "# Add subject labels\n",
    "for i in range(n_subjects):\n",
    "    ax.annotate(f'S{i+1}', (subject_accuracies[i], results_loso.cv_scores[i]),\n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Add identity line\n",
    "lims = [0.4, 1.0]\n",
    "ax.plot(lims, lims, 'k--', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Within-Subject Accuracy')\n",
    "ax.set_ylabel('LOSO Accuracy')\n",
    "ax.set_title(f'Pattern Consistency (r = {correlation:.2f})')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Publication-Ready Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate publication-ready statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"GROUP DECODING ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nWithin-Subject Analysis (N={n_subjects}):\")\n",
    "print(f\"  Accuracy: {np.mean(subject_accuracies):.1%} ± {np.std(subject_accuracies):.1%}\")\n",
    "print(f\"  Range: [{np.min(subject_accuracies):.1%}, {np.max(subject_accuracies):.1%}]\")\n",
    "print(f\"  t({n_subjects-1}) = {t_stat:.2f}, p = {p_value:.4f}\")\n",
    "print(f\"  95% CI: [{ci_lower:.1%}, {ci_upper:.1%}]\")\n",
    "\n",
    "print(f\"\\nLeave-One-Subject-Out Analysis:\")\n",
    "print(f\"  Accuracy: {results_loso.accuracy:.1%} ± {results_loso.cv_std:.1%}\")\n",
    "\n",
    "print(f\"\\nPattern Consistency:\")\n",
    "print(f\"  Within-Subject vs LOSO: r = {correlation:.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "1. **Within-subject decoding**: Standard single-subject analysis\n",
    "2. **Group statistics**: t-tests, bootstrap CIs\n",
    "3. **LOSO analysis**: Cross-subject generalization\n",
    "4. **Pattern consistency**: Subject-specific vs. common patterns\n",
    "\n",
    "## Key Considerations\n",
    "\n",
    "- **Within-subject > LOSO**: Subject-specific patterns dominate\n",
    "- **Within-subject ≈ LOSO**: Common patterns across subjects\n",
    "- **High variability**: Consider individual differences analysis\n",
    "- **Report both**: Within-subject AND LOSO for complete picture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
