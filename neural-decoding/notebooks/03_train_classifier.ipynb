{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Training Classifiers\n",
    "\n",
    "This notebook demonstrates training different classifiers for neural decoding.\n",
    "\n",
    "**Contents:**\n",
    "1. SVM Decoder\n",
    "2. Random Forest Decoder\n",
    "3. Logistic Regression\n",
    "4. LDA Decoder\n",
    "5. Ensemble Methods\n",
    "6. Comparing Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from core.dataset import DecodingDataset\n",
    "from models.classifiers import (\n",
    "    SVMDecoder, \n",
    "    RandomForestDecoder, \n",
    "    LogisticDecoder, \n",
    "    LDADecoder,\n",
    "    EnsembleDecoder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic neuroimaging-like data\n",
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=1000,\n",
    "    n_informative=50,\n",
    "    n_redundant=50,\n",
    "    n_classes=2,\n",
    "    class_sep=0.8,  # Some overlap between classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "groups = np.repeat(np.arange(1, 6), 40)  # 5 runs\n",
    "\n",
    "dataset = DecodingDataset(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    groups=groups,\n",
    "    class_names=[\"class_A\", \"class_B\"],\n",
    "    modality=\"fmri\"\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {dataset.n_samples} samples, {dataset.n_features} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM Decoder\n",
    "\n",
    "Linear SVM is the default choice for high-dimensional neuroimaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM (recommended for fMRI)\n",
    "svm_linear = SVMDecoder(\n",
    "    kernel=\"linear\",\n",
    "    C=1.0,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "# Cross-validate\n",
    "results_svm = svm_linear.cross_validate(dataset)\n",
    "\n",
    "print(f\"SVM Linear: {results_svm.accuracy:.1%} (+/- {results_svm.cv_std:.1%})\")\n",
    "print(f\"Per-class: {results_svm.accuracy_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF SVM (for non-linear patterns)\n",
    "svm_rbf = SVMDecoder(\n",
    "    kernel=\"rbf\",\n",
    "    C=1.0,\n",
    "    gamma=\"scale\"\n",
    ")\n",
    "\n",
    "results_rbf = svm_rbf.cross_validate(dataset)\n",
    "print(f\"SVM RBF: {results_rbf.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances (weights) for linear SVM\n",
    "svm_linear.fit(dataset.X, dataset.y)\n",
    "weights = svm_linear.get_feature_importances()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(weights, bins=50)\n",
    "plt.xlabel('Weight Magnitude')\n",
    "plt.ylabel('Count')\n",
    "plt.title('SVM Feature Weights Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Decoder\n",
    "\n",
    "Good for non-linear patterns and interpretable feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_decoder = RandomForestDecoder(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "results_rf = rf_decoder.cross_validate(dataset)\n",
    "print(f\"Random Forest: {results_rf.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances (Gini)\n",
    "rf_decoder.fit(dataset.X, dataset.y)\n",
    "importances = rf_decoder.get_feature_importances()\n",
    "\n",
    "# Top 20 features\n",
    "top_idx = np.argsort(importances)[::-1][:20]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(20), importances[top_idx][::-1])\n",
    "plt.yticks(range(20), [f\"Feature {i}\" for i in top_idx[::-1]])\n",
    "plt.xlabel('Gini Importance')\n",
    "plt.title('Top 20 Features (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with L2 penalty\n",
    "lr_decoder = LogisticDecoder(\n",
    "    C=1.0,\n",
    "    penalty=\"l2\",\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "results_lr = lr_decoder.cross_validate(dataset)\n",
    "print(f\"Logistic Regression: {results_lr.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 penalty for sparse solutions\n",
    "lr_sparse = LogisticDecoder(\n",
    "    C=0.1,\n",
    "    penalty=\"l1\"\n",
    ")\n",
    "\n",
    "results_sparse = lr_sparse.cross_validate(dataset)\n",
    "print(f\"Logistic (L1 sparse): {results_sparse.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LDA Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "lda_decoder = LDADecoder(\n",
    "    solver=\"svd\",\n",
    "    shrinkage=None\n",
    ")\n",
    "\n",
    "results_lda = lda_decoder.cross_validate(dataset)\n",
    "print(f\"LDA: {results_lda.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Methods\n",
    "\n",
    "Combine multiple classifiers for improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble with soft voting\n",
    "ensemble = EnsembleDecoder(\n",
    "    decoders=[\n",
    "        SVMDecoder(kernel=\"linear\"),\n",
    "        RandomForestDecoder(n_estimators=100),\n",
    "        LogisticDecoder()\n",
    "    ],\n",
    "    voting=\"soft\",  # Average probabilities\n",
    "    weights=None    # Equal weights\n",
    ")\n",
    "\n",
    "results_ensemble = ensemble.cross_validate(dataset)\n",
    "print(f\"Ensemble: {results_ensemble.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted ensemble\n",
    "ensemble_weighted = EnsembleDecoder(\n",
    "    decoders=[\n",
    "        SVMDecoder(kernel=\"linear\"),\n",
    "        RandomForestDecoder(n_estimators=100),\n",
    "        LogisticDecoder()\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[2, 1, 1]  # Give SVM more weight\n",
    ")\n",
    "\n",
    "results_weighted = ensemble_weighted.cross_validate(dataset)\n",
    "print(f\"Weighted Ensemble: {results_weighted.accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "results = {\n",
    "    'SVM Linear': results_svm,\n",
    "    'SVM RBF': results_rbf,\n",
    "    'Random Forest': results_rf,\n",
    "    'Logistic L2': results_lr,\n",
    "    'LDA': results_lda,\n",
    "    'Ensemble': results_ensemble\n",
    "}\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "names = list(results.keys())\n",
    "accuracies = [r.accuracy for r in results.values()]\n",
    "stds = [r.cv_std for r in results.values()]\n",
    "\n",
    "x = np.arange(len(names))\n",
    "bars = ax.bar(x, accuracies, yerr=stds, capsize=5, color='steelblue', edgecolor='black')\n",
    "\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', label='Chance')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Classifier Comparison')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "            f'{acc:.1%}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed summary\n",
    "print(\"Classifier Comparison\")\n",
    "print(\"=\"*50)\n",
    "for name, result in results.items():\n",
    "    print(f\"{name:20s}: {result.accuracy:.1%} (+/- {result.cv_std:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for best classifier\n",
    "best_result = results_svm\n",
    "best_result.plot_confusion_matrix(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV scores\n",
    "best_result.plot_cv_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **04_cross_validation.ipynb**: Advanced CV strategies\n",
    "- **05_searchlight.ipynb**: Whole-brain searchlight analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
