{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Feature Extraction and Selection\n",
    "\n",
    "This notebook demonstrates feature extraction and selection methods\n",
    "for neural decoding.\n",
    "\n",
    "**Contents:**\n",
    "1. ROI extraction\n",
    "2. Time window extraction (EEG)\n",
    "3. Trial averaging\n",
    "4. Feature selection (ANOVA, RFE, Stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from core.dataset import DecodingDataset\n",
    "from features.extractors import ROIExtractor, TimeWindowExtractor, TrialAverager\n",
    "from features.selectors import ANOVASelector, RFESelector, StabilitySelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic fMRI-like data\n",
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=5000,  # Many voxels\n",
    "    n_informative=100,\n",
    "    n_redundant=100,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "groups = np.repeat(np.arange(1, 6), 40)  # 5 runs\n",
    "\n",
    "dataset = DecodingDataset(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    groups=groups,\n",
    "    feature_names=[f\"voxel_{i}\" for i in range(5000)],\n",
    "    class_names=[\"class_A\", \"class_B\"],\n",
    "    modality=\"fmri\"\n",
    ")\n",
    "\n",
    "print(f\"Original: {dataset.n_samples} samples, {dataset.n_features} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ANOVA Feature Selection\n",
    "\n",
    "Select features with highest F-scores from one-way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 500 features by ANOVA F-score\n",
    "anova_selector = ANOVASelector(k=500)\n",
    "\n",
    "# Fit on data\n",
    "anova_selector.fit(dataset.X, dataset.y)\n",
    "\n",
    "# Transform\n",
    "X_selected = anova_selector.transform(dataset.X)\n",
    "print(f\"After ANOVA: {X_selected.shape[1]} features\")\n",
    "\n",
    "# Or use transform_dataset for full dataset\n",
    "selected_dataset = anova_selector.transform_dataset(dataset)\n",
    "print(f\"Selected dataset: {selected_dataset.n_features} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check F-scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = anova_selector.get_scores()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(scores, bins=50)\n",
    "plt.xlabel('F-score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('ANOVA F-score Distribution')\n",
    "plt.axvline(x=np.sort(scores)[-500], color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RFE Feature Selection\n",
    "\n",
    "Recursive Feature Elimination using classifier weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First reduce with ANOVA, then RFE\n",
    "# (RFE is slow on many features)\n",
    "\n",
    "# Pre-select with ANOVA\n",
    "anova = ANOVASelector(k=1000)\n",
    "anova.fit(dataset.X, dataset.y)\n",
    "X_pre = anova.transform(dataset.X)\n",
    "\n",
    "# RFE to select final features\n",
    "rfe_selector = RFESelector(\n",
    "    n_features=100,\n",
    "    step=0.2,  # Remove 20% of features each step\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rfe_selector.fit(X_pre, dataset.y)\n",
    "X_rfe = rfe_selector.transform(X_pre)\n",
    "\n",
    "print(f\"After RFE: {X_rfe.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature rankings\n",
    "rankings = rfe_selector.get_ranking()\n",
    "print(f\"Best features (rank=1): {np.sum(rankings == 1)}\")\n",
    "print(f\"Ranking range: {rankings.min()} to {rankings.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stability Selection\n",
    "\n",
    "Select features consistently chosen across bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability selection\n",
    "stability_selector = StabilitySelector(\n",
    "    n_bootstrap=50,\n",
    "    sample_fraction=0.75,\n",
    "    threshold=0.6,  # Select features chosen in >60% of bootstraps\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Use ANOVA pre-selected features\n",
    "stability_selector.fit(X_pre, dataset.y)\n",
    "X_stable = stability_selector.transform(X_pre)\n",
    "\n",
    "print(f\"Stable features: {X_stable.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability scores\n",
    "stability_scores = stability_selector.get_stability_scores()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(stability_scores, bins=30)\n",
    "plt.xlabel('Selection Frequency')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Feature Stability Scores')\n",
    "plt.axvline(x=0.6, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trial Averaging\n",
    "\n",
    "Average multiple trials to increase SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average every 5 trials within each class\n",
    "averager = TrialAverager(n_per_average=5, random_state=42)\n",
    "\n",
    "averaged_dataset = averager.fit_transform(dataset)\n",
    "\n",
    "print(f\"Before averaging: {dataset.n_samples} samples\")\n",
    "print(f\"After averaging: {averaged_dataset.n_samples} samples\")\n",
    "print(f\"Trials per average: {averaged_dataset.metadata['n_per_average']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time Window Extraction (EEG)\n",
    "\n",
    "Extract features from specific time windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic EEG-like data\n",
    "n_epochs = 100\n",
    "n_channels = 64\n",
    "n_times = 200  # 1 second at 200 Hz\n",
    "\n",
    "# Simulate EEG: (n_epochs, n_channels, n_times) -> flatten\n",
    "X_eeg = np.random.randn(n_epochs, n_channels * n_times)\n",
    "y_eeg = np.random.randint(0, 2, n_epochs)\n",
    "\n",
    "eeg_dataset = DecodingDataset(\n",
    "    X=X_eeg,\n",
    "    y=y_eeg,\n",
    "    metadata={\n",
    "        \"n_channels\": n_channels,\n",
    "        \"n_times\": n_times,\n",
    "        \"sfreq\": 200,\n",
    "        \"tmin\": -0.2,\n",
    "        \"tmax\": 0.8\n",
    "    },\n",
    "    modality=\"eeg\"\n",
    ")\n",
    "\n",
    "print(f\"EEG dataset: {eeg_dataset.n_samples} epochs, {eeg_dataset.n_features} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific time windows\n",
    "window_extractor = TimeWindowExtractor(\n",
    "    windows=[\n",
    "        (0.1, 0.2),   # P1 component\n",
    "        (0.15, 0.25), # N170\n",
    "        (0.3, 0.5),   # P300\n",
    "    ],\n",
    "    aggregation=\"mean\",\n",
    "    flatten=True\n",
    ")\n",
    "\n",
    "window_extractor.fit(eeg_dataset)\n",
    "windowed_dataset = window_extractor.transform(eeg_dataset)\n",
    "\n",
    "print(f\"Original: {eeg_dataset.n_features} features\")\n",
    "print(f\"After windowing: {windowed_dataset.n_features} features\")\n",
    "print(f\"Windows: {windowed_dataset.metadata['windows']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline: Combined Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create feature processing pipeline\n",
    "feature_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('anova', ANOVASelector(k=500)),\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "X_processed = feature_pipeline.fit_transform(dataset.X, dataset.y)\n",
    "print(f\"Processed shape: {X_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **03_train_classifier.ipynb**: Training decoders with selected features\n",
    "- **04_cross_validation.ipynb**: Proper CV with feature selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
